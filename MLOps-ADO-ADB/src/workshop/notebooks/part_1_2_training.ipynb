{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f775ddb6-7daf-4f9f-99fa-7fc024351b47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 1: Model Training\n",
    "\n",
    "The Part 0 notebook sets up a raw file to be used for model training and validation.\n",
    "\n",
    "The Part 1 Data Prep notebook handles data preparation and quality checking steps. \n",
    "\n",
    "This notebook focuses on model training, making use of the data prepared in the data prep notebook that will run as a previous job in the workflow.\n",
    "\n",
    "The notebook will handle the following steps:\n",
    "- Split the prepared data into training and validation datasets.\n",
    "- Build a simple classifier to predict wine quality based on the available features in the data.\n",
    "- Register the model in MLflow as the baseline model that we'll try to beat by changing parts of the model development workflow\n",
    "\n",
    "When these steps complete, we have a baseline model that can generate predictions of the quality of Portugese wines based on the wine's measured physicochemical properties. \n",
    "\n",
    "## Requirements\n",
    "This tutorial requires Databricks Runtime for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c482f0a0-9ba5-455c-846e-9a93734a18d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Multiple people may be running this workshop at the same time.  We want each\n",
    "# participant to have their own set of files.  To create your own file storage area,\n",
    "# put your name below:\n",
    "\n",
    "your_name = \"\"\n",
    "\n",
    "try: run_name = dbutils.widgets.get(\"run_name\")\n",
    "except: run_name = your_name.strip()\n",
    "run_name = \"no_name\" if run_name == \"\" else run_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "953f4f1f-405b-44e1-863b-600e6f2bc94f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load the prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf02fb6-5f66-4a73-a166-d51137f7509c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(f\"/dbfs/tutorials/wine-data/{run_name}/wine-quality-all-prepped.csv\")\n",
    "data = data.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "379abb9a-bd5b-46b9-8975-ce91858eba39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Split dataset for training baseline model\n",
    "Split the input data into 3 sets:\n",
    "- Train (60% of the dataset used to train the model)\n",
    "- Validation (20% of the dataset used to tune the hyperparameters)\n",
    "- Test (20% of the dataset used to report the true performance of the model on an unseen dataset)\n",
    "\n",
    "The test dataset will not be used in this model training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70c1c07-0048-4bb8-a0c3-17a7895bb4b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop([\"quality\"], axis=1)\n",
    "y = data.quality\n",
    "\n",
    "# Split out the training data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6, random_state=123)\n",
    "\n",
    "# Split the remaining data equally into validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "224d0ddf-3925-4849-bc20-564175c212e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Build a baseline model\n",
    "This task seems well suited to a random forest classifier, since the output is binary and there may be interactions between multiple variables.\n",
    "\n",
    "The following code builds a simple classifier using scikit-learn. It uses MLflow to keep track of the model accuracy, and to save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea321ffb-7fc4-4f8a-9517-157b6c823341",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "mkdir -p /Workspace/Shared/wine_quality/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46af6002-8063-4ada-b7e5-6ce56c22f60a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "import cloudpickle\n",
    "import time\n",
    "\n",
    "# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). \n",
    "# The following code creates a wrapper function, SklearnModelWrapper, that uses \n",
    "# the predict_proba method to return the probability that the observation belongs to each class. \n",
    "\n",
    "class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    \n",
    "  def predict(self, context, model_input):\n",
    "    return self.model.predict_proba(model_input)[:,1]\n",
    "\n",
    "mlflow.set_experiment(f\"/Shared/wine_quality/experiments/{run_name}\")\n",
    "# mlflow.start_run creates a new MLflow run to track the performance of this model. \n",
    "# Within the context, you call mlflow.log_param to keep track of the parameters used, and\n",
    "# mlflow.log_metric to record metrics like accuracy.\n",
    "with mlflow.start_run(run_name='untuned_random_forest'):\n",
    "  n_estimators = 10\n",
    "  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]\n",
    "  predictions_test = model.predict_proba(X_test)[:,1]\n",
    "  auc_score = roc_auc_score(y_test, predictions_test)\n",
    "  mlflow.log_param('n_estimators', n_estimators)\n",
    "  # Use the area under the ROC curve as a metric.\n",
    "  mlflow.log_metric('auc', auc_score)\n",
    "  wrappedModel = SklearnModelWrapper(model)\n",
    "  # Log the model with a signature that defines the schema of the model's inputs and outputs. \n",
    "  # When the model is deployed, this signature will be used to validate inputs.\n",
    "  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))\n",
    "  \n",
    "  # MLflow contains utilities to create a conda environment used to serve models.\n",
    "  # The necessary dependencies are added to a conda.yaml file which is logged along with the model.\n",
    "  conda_env =  _mlflow_conda_env(\n",
    "        additional_conda_deps=None,\n",
    "        additional_pip_deps=[\"cloudpickle=={}\".format(cloudpickle.__version__), \"scikit-learn=={}\".format(sklearn.__version__)],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "  mlflow.pyfunc.log_model(\"model\", python_model=wrappedModel, conda_env=conda_env, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "867b3e23-9147-4ca4-b2d2-f1103c471d53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Examine the learned feature importances output by the model as a sanity-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e174abe-774b-461e-b390-212e11d1c68d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns.tolist(), columns=['importance'])\n",
    "feature_importances.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06a939b8-7232-464b-8370-2bc9e3a8c613",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As illustrated by the boxplots shown previously, both alcohol and density are important in predicting quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8981b9f-8833-4dc4-a1cb-b25f9f43a8c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You logged the Area Under the ROC Curve (AUC) to MLflow. Click **Experiment** at the upper right to display the Experiment Runs sidebar. \n",
    "\n",
    "The model achieved an AUC of 0.854.\n",
    "\n",
    "A random classifier would have an AUC of 0.5, and higher AUC values are better. For more information, see [Receiver Operating Characteristic Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d1df4d8-4b50-47d8-ad89-d3c80ce960ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Register the model in MLflow Model Registry\n",
    "\n",
    "By registering this model in Model Registry, you can easily reference the model from anywhere within Databricks.\n",
    "\n",
    "The following section shows how to do this programmatically, but you can also register a model using the UI. See \"[Create or register a model using the UI](https://docs.microsoft.com/azure/databricks/applications/machine-learning/manage-model-lifecycle/index#create-or-register-a-model-using-the-ui)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f7b7e14-b016-41c1-9852-aae0f6625e93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_id = mlflow.search_runs(filter_string='tags.mlflow.runName = \"untuned_random_forest\"').iloc[0].run_id\n",
    "\n",
    "# uncomment when incorporating hyperparameter search code in Part 4\n",
    "# best_run = mlflow.search_runs(order_by=['metrics.auc DESC']).iloc[0]\n",
    "# print(f'AUC of Best Run: {best_run[\"metrics.auc\"]}')\n",
    "# run_id = best_run.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4774edbf-f3fb-495c-a638-ec63f275f885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If you see the error \"PERMISSION_DENIED: User does not have any permission level assigned to the registered model\", \n",
    "# the cause may be that a model already exists with the name \"wine_quality\". Try using a different name.\n",
    "\n",
    "# to create your own version of the model, uncomment the next line, and comment the line after\n",
    "# model_name = f\"wine_quality-{run_name}\"\n",
    "model_name = \"wine_quality\"\n",
    "model_version = mlflow.register_model(f\"runs:/{run_id}/model\", model_name)\n",
    "\n",
    "# Registering the model takes a few seconds, so add a small delay\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46f16d91-13ad-4e28-866f-3a979eb6fde1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You should now see the model in the Models page. To display the Models page, click the Models icon in the left sidebar. \n",
    "\n",
    "Next, transition this model to staging and load it into this notebook from Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb032bd6-7e9d-4430-8c13-895ebc189297",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "  name=model_name,\n",
    "  version=model_version.version,\n",
    "  stage=\"Staging\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f284978e-9c9b-4cd2-8bdc-1393991c5701",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The Models page now shows the model version in stage \"Staging\".\n",
    "\n",
    "You can now refer to the model using the path \"models:/wine_quality-{yourname}/staging\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b22211-62ea-4fdd-a6ff-c552a65fa6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}/staging\")\n",
    "\n",
    "# Sanity-check: This should match the AUC logged by MLflow\n",
    "print(f'AUC: {roc_auc_score(y_test, model.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "673ef4b4-6d74-4fe9-af77-a013148060ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1569140396715336,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "part_1_2_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42da3deb-616c-47da-ba93-a9259704ce36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Batch inference\n",
    "\n",
    "There are many scenarios where you might want to evaluate a model on a corpus of new data. For example, you may have a fresh batch of data, or may need to compare the performance of two models on the same corpus of data.\n",
    "\n",
    "The following code evaluates the model on data stored in a Delta table, using Spark to run the computation in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44a3d2ba-1285-460e-be14-a060c06de364",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To simulate a new corpus of data, save the existing X_train data to a Delta table. \n",
    "# In the real world, this would be a new batch of data.\n",
    "spark_df = spark.createDataFrame(X_train)\n",
    "table_path = \"dbfs:/tutorials/wine-data/delta\"\n",
    "\n",
    "# Delete the contents of this path in case this cell has already been run\n",
    "dbutils.fs.rm(table_path, True)\n",
    "spark_df.write.format(\"delta\").save(table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a033adeb-5af8-403e-8c68-75dd829caedf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Load the model into a Spark UDF, so it can be applied to the Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5a7251e-ef02-4eb3-8c51-52ed6faa8abf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "apply_model_udf = mlflow.pyfunc.spark_udf(spark, f\"models:/{model_name}/production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7beb5d22-6dcd-4a6c-80fb-6ca88808ccfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the \"new data\" from Delta\n",
    "new_data = spark.read.format(\"delta\").load(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39e22812-2516-48e6-9735-21bff0fcbf29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8087a6e1-511d-4c5b-895c-34539ed004a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "# Apply the model to the new data\n",
    "udf_inputs = struct(*(X_train.columns.tolist()))\n",
    "\n",
    "new_data = new_data.withColumn(\n",
    "  \"prediction\",\n",
    "  apply_model_udf(udf_inputs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c451842f-0280-4900-9e6f-4bd425e8c139",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Each row now has an associated prediction. Note that the xgboost function does not output probabilities by default, so the predictions are not limited to the range [0, 1].\n",
    "display(new_data)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "part_1_4_scoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
